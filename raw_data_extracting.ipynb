{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers_and_variables as hlp\n",
    "import nlp as nlp_hlp\n",
    "import ML_helpers as ml_hlp\n",
    "import shap\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "# import pixiedust\n",
    "# %%pixie_debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### done this on word2vec pretrained to 7b and 63d dicts saved\n",
    "\n",
    "# dataPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/PekLUng_20210503sav.xlsx\"\n",
    "# password = None#\n",
    "# rawdataDF = hlp.get_exL_df(stringPath=dataPath, password=password, sheetNum=1)\n",
    "# rawdataDF = rawdataDF.iloc[1: , :]\n",
    "# dataInfoPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/Datainformation_minroAdjusted.xlsx\"\n",
    "# dataInfoDF = hlp.get_cleaned_dataInfo_df(dataInfoPath)\n",
    "# katInfoDF = hlp.get_cleaned_katInfo_df(dataInfoPath)\n",
    "# dict_of_katInfo = hlp.get_dict_of_katInfoDF(katInfoDF)\n",
    "# dict_of_dataInfo = hlp.get_dict_of_dataInfoDF(dataInfoDF)\n",
    "\n",
    "# rawdataDF, labels = hlp.get_labels_and_indices_unlabeled_patients(rawdataDF)\n",
    "\n",
    "# # copy_rawdata =  hlp.get_dataframe_without_cols(rawdataDF, columns_tobe_removed=None, remove_cols_with_dates=True)\n",
    "# levitsky_rawdata = hlp.get_dataframe_with_specific_cols(rawdataDF)\n",
    "# del rawdataDF\n",
    "\n",
    "# backgroud_variables = levitsky_rawdata[levitsky_rawdata.columns[0:8]]\n",
    "# descriptors = levitsky_rawdata[levitsky_rawdata.columns[8:]]\n",
    "# descriptors.insert(0, column=levitsky_rawdata.columns[0], value=levitsky_rawdata[levitsky_rawdata.columns[0]],\n",
    "#                    allow_duplicates=False)\n",
    "\n",
    "# ##############################################\n",
    "# data_frame_to_clean = descriptors\n",
    "# main_dict, ind_num_removed_features = hlp.get_dict_of_questions_answers(data_frame_to_clean, \n",
    "#                                                                         dataInfoDF, \n",
    "#                                                                         katInfoDF, \n",
    "#                                                                         amount_data =None ,\n",
    "#                                                                         clear_missings_or_Non=True,\n",
    "#                                                                         clear_ques_with_negative_answeres=False)\n",
    "# max_num_feature_removed = 0\n",
    "# ind_of_max_feature_removed = 0\n",
    "\n",
    "# for ind, count in ind_num_removed_features:\n",
    "#     if count > max_num_feature_removed:\n",
    "#         max_num_feature_removed = count\n",
    "#         ind_of_max_feature_removed = ind\n",
    "# print(\"Most number of features removed from a patient is: \", max_num_feature_removed)\n",
    "# print(\"Patient index with most removed features is: \", ind_of_max_feature_removed)\n",
    "# print(\"Patient number or id: {0}, with remaining number of features: {1}\".format(str(int(data_frame_to_clean.iloc[ind_of_max_feature_removed][0])), len(main_dict[str(int(data_frame_to_clean.iloc[ind_of_max_feature_removed][0]))])))\n",
    "# print(\"\\nTotal length of the main dictionary, number of patients: \", len(main_dict))\n",
    "\n",
    "# #############################################\n",
    "# dict_path = \"C:/Users/a7mad/Desktop/MEX/PekLung/\"\n",
    "# hlp.write_dict_as_json_file(main_dict, dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read the row data as pd data frame\n",
    "\"\"\"\n",
    "dataPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/PekLUng_20210503sav.xlsx\"\n",
    "# password = #\n",
    "rawdataDF = hlp.get_exL_df(stringPath=dataPath, password=password, sheetNum=1)\n",
    "\"\"\" \n",
    "read the data info as pd data frame\n",
    "\"\"\"\n",
    "dataInfoPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/Datainformation_minroAdjusted.xlsx\"\n",
    "dataInfoDF = hlp.get_cleaned_dataInfo_df(dataInfoPath)\n",
    "katInfoDF = hlp.get_cleaned_katInfo_df(dataInfoPath)\n",
    "\"\"\"\n",
    "get dictionary of data information from data info data fram\n",
    "\"\"\"\n",
    "dict_of_katInfo = hlp.get_dict_of_katInfoDF(katInfoDF)\n",
    "dict_of_dataInfo = hlp.get_dict_of_dataInfoDF(dataInfoDF)\n",
    "\"\"\" \n",
    "Get the labels, under name Lungcancer_Num\n",
    "check whether labels are 1=yes LC or 2=No LC and check STUDY_1 if valid, remove unlabeled and invalid patients\n",
    "\n",
    "\"\"\"\n",
    "rawdataDF, labels, removed_indices = hlp.get_labels_and_indices_unlabeled_patients(rawdataDF)\n",
    "\"\"\"\n",
    "Remove features, which includes information about the label, like diagnos2, aslo modules names\n",
    "DiagnosticInvestigation (need to be discussed, since it includes dignostic which means non early prediction).\n",
    "columns_tobe_removed=None --> predefind columns will be removed, see the function in helpers_and_variables file.\n",
    "remove_cols_with_dates=True --> removes all columns with dates(this is relevance in case of tfidf), \n",
    "otherwise consider using converting dates to days, see function hlp.get_dates_in_days() in next cell.\n",
    "\"\"\"\n",
    "rawdataDF =  hlp.get_dataframe_without_cols(rawdataDF, columns_tobe_removed=None, remove_cols_with_dates=False)\n",
    "\n",
    "copy_rawdata = pd.DataFrame.copy(rawdataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nlp levitsky data\n",
    "ages = levitsky_rawdata['Age']\n",
    "# sns.displot(ages)\n",
    "df1 = pd.DataFrame(10*np.random.randn(len(ages), 1))\n",
    "df1['Age'] = levitsky_rawdata['Age'].values\n",
    "# df1['Age'] \n",
    "conds = [df1.values <= 40.0 , df1.values <= 65.0,  df1.values <= 85.0 , df1.values > 85.0]\n",
    "choices = ['under40Years', '40To65Years', '65To85Years', 'Over85Years']\n",
    "\n",
    "df1 = pd.DataFrame(np.select(conds, choices, default='zero'),\n",
    "             index=levitsky_rawdata.index,\n",
    "             columns=df1.columns)\n",
    "\n",
    "nlp_levitsky_rawdata = pd.DataFrame.copy(levitsky_rawdata) \n",
    "nlp_levitsky_rawdata['Age'] = df1['Age']\n",
    "\n",
    "del df1, ages, conds, choices\n",
    "\n",
    "nlp_backgroud_variables = nlp_levitsky_rawdata[nlp_levitsky_rawdata.columns[0:8]]\n",
    "nlp_descriptors = nlp_levitsky_rawdata[nlp_levitsky_rawdata.columns[8:]]\n",
    "nlp_descriptors.insert(0, column=nlp_levitsky_rawdata.columns[0],value=nlp_levitsky_rawdata[nlp_levitsky_rawdata.columns[0]], allow_duplicates=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you wish to convert the dates into days, done only if you still have the dates columns\n",
    "\"\"\"\n",
    "# copy_rawdata = hlp.get_dates_in_days(copy_rawdata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display the whole data frame\n",
    "\"\"\"\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(katInfoDF)\n",
    "# copy_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test different methods in hlp and extract information from the data\n",
    "\"\"\"\n",
    "# list_of_vars = katInfoDF['Variable'].tolist()\n",
    "# list_of_labels = katInfoDF['Label'].tolist()\n",
    "# list_of_values = katInfoDF['Value'].tolist()\n",
    "\n",
    "# list_of_questions = dataInfoDF['Label'].tolist()\n",
    "# list_of_quesNams = dataInfoDF['Variable'].tolist()\n",
    "\n",
    "# cleanedListOfStrings = nlp_hlp.get_cleaned_list_of_strings(list_of_questions, stemm=True)\n",
    "# cleanedListOfStrings\n",
    "# cleanedWordsArray = hlp.get_array_of_words(cleanedListOfStrings)\n",
    "\n",
    "\"\"\"\n",
    "get a list with qustions and answers for one patient\n",
    "\"\"\"\n",
    "# list_ques_answers = list(main_dict['1001'].values())\n",
    "# list_cleaned_ques_answers = nlp_hlp.get_cleaned_list_of_strings(list_ques_answers,stemm=False)\n",
    "# token_words_array = hlp.get_array_of_words(list_cleaned_ques_answers)\n",
    "# unique_token_words = np.unique(token_words_array, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save to a csv or another excel file\n",
    "\"\"\"\n",
    "# copy_rawdata.to_csv('C:/Users/a7mad/Desktop/MEX/PekLung/dates_adjusted.csv')\n",
    "# copy_rawdata.to_excel('C:/Users/a7mad/Desktop/MEX/PekLung/dates_adjusted_excel.xlsx')\n",
    "\n",
    "# x = pd.read_csv('dates_adjusted.csv')\n",
    "# x = pd.read_excel('dates_adjusted_excel.xlsx')\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(df_dates_before)\n",
    "# display(df_dates_before)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):    \n",
    "#     display(df_dates_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most number of features removed from a one patient is:  566\n",
      "Patient index with most removed features is:  10\n",
      "Patient number or id: 1013, with remaining number of features: 113\n",
      "\n",
      "Total length of the main dictionary, number of patients:  506\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "get a dictionary of each patient according to this format:\n",
    "{Patient number: {questions name, the questions text, corresponding answers}}\n",
    "If clear_missings_or_Non true, it clears questions (features),\n",
    "where answeres are missing or the answers is no/missing.\n",
    "amount_data = None --> all data is considered\n",
    "\"\"\"\n",
    "main_dict, ind_num_removed_features = hlp.get_dict_of_questions_answers(copy_rawdata, \n",
    "                                                                        dataInfoDF, \n",
    "                                                                        katInfoDF, \n",
    "                                                                        amount_data = None,\n",
    "                                                                        clear_missings_or_Non=True,\n",
    "                                                                        clear_ques_with_negative_answeres=False)\n",
    "\"\"\"\n",
    "check how many features were removed by get_dict_of_questions_answers()\n",
    "\n",
    "\"\"\"\n",
    "max_num_feature_removed = 0\n",
    "ind_of_max_feature_removed = 0\n",
    "\n",
    "for ind, count in ind_num_removed_features:\n",
    "    if count > max_num_feature_removed:\n",
    "        max_num_feature_removed = count\n",
    "        ind_of_max_feature_removed = ind\n",
    "print(\"Most number of features removed from a one patient is: \", max_num_feature_removed)\n",
    "print(\"Patient index with most removed features is: \", ind_of_max_feature_removed)\n",
    "print(\"Patient number or id: {0}, with remaining number of features: {1}\".format(str(int(rawdataDF.loc[ind_of_max_feature_removed][0])), len(main_dict[str(int(rawdataDF.loc[ind_of_max_feature_removed][0]))])))\n",
    "print(\"\\nTotal length of the main dictionary, number of patients: \", len(main_dict))\n",
    "#main_dict[str(int(rawdataDF.loc[ind_of_max_feature_removed][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In case you need to write/save the dictionary\n",
    "\"\"\"\n",
    "save_dict_path = \"C:/Users/a7mad/Desktop/MEX/PekLung/dict\"\n",
    "# save_dict_path = \"C:/Users/a7mad/Desktop/MEX/PekLung/dict_nodates\"\n",
    "# save_dict_path = \"C:/Users/a7mad/Desktop/MEX/PekLung/dict_removed_nos_nodates\"\n",
    "# labels_path = \"C:/Users/a7mad/Desktop/MEX/PekLung/labels\"\n",
    "\n",
    "hlp.write_dict_as_json_file(main_dict, file_path=save_dict_path)\n",
    "# hlp.write_list_as_json_file(labels, file_path=labels_path)\n",
    "js = hlp.load_dict_from_json_file(file_path=save_dict_path)\n",
    "# lbl = hlp.load_list_from_json_file(file_path=labels_path)\n",
    "# print(lbl == labels)\n",
    "print(js==main_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
