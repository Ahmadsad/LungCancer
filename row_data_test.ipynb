{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers_and_variables as hlp\n",
    "import ML_helpers as ml_hlp\n",
    "import shap\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "# import pixiedust\n",
    "# %%pixie_debuggerR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read the row data as pd data frame\n",
    "\"\"\"\n",
    "dataPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/PekLUng_20210503sav.xlsx\"\n",
    "password = \"d46cf574-84e1-11ec-a8a3-0242ac120002\" #\n",
    "rowdataDF = hlp.get_exL_df(stringPath=dataPath, password=password, sheetNum=1)\n",
    "\"\"\" \n",
    "read the data info as pd data frame\n",
    "\"\"\"\n",
    "dataInfoPath = \"C:/Users/a7mad/Desktop/MEX/PekLung/Datainformation_minroAdjusted.xlsx\"\n",
    "dataInfoDF = hlp.get_cleaned_dataInfo_df(dataInfoPath)\n",
    "katInfoDF = hlp.get_cleaned_katInfo_df(dataInfoPath)\n",
    "\"\"\"\n",
    "get dictionary of data information from data info data fram\n",
    "\"\"\"\n",
    "dict_of_katInfo = hlp.get_dict_of_katInfoDF(katInfoDF)\n",
    "dict_of_dataInfo = hlp.get_dict_of_dataInfoDF(dataInfoDF)\n",
    "\"\"\" \n",
    "Get the labels, under name Lungcancer_Num\n",
    "check whether labels are 1=yes LC or 2=No LC \n",
    "and get patient with other labels (missing or other diagnoses) removed, total 25 patients\n",
    "\"\"\"\n",
    "rowdataDF, labels, removed_indices = hlp.get_labels_and_indicesOfUnlabeledPatients(rowdataDF)\n",
    "\"\"\" \n",
    "Get the labels, under name Lungcancer_Num\n",
    "check whether labels are 1=yes LC or 2=No LC \n",
    "and get patient with other labels (missing or other diagnoses) removed, total 25 patients\n",
    "\"\"\"\n",
    "rowdataDF, labels, removed_indices = hlp.get_labels_and_indicesOfUnlabeledPatients(rowdataDF)\n",
    "\"\"\"\n",
    "Remove the first features, which includes information about the label, like diagnos2, aslo modules names\n",
    "DiagnosticInvestigation (need to be discussed, since it includes dignostic which means non early prediction)\n",
    "\"\"\"\n",
    "rowdataDF =  hlp.get_cleanedCol_rowData_df(rowdataDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_rowdata = pd.DataFrame.copy(rowdataDF)\n",
    "copy_rowdata = hlp.get_dates_in_days(copy_rowdata)\n",
    "# copy_rowdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nget a list with qustions and answers for one patient\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_of_vars = katInfoDF['Variable'].tolist()\n",
    "# list_of_labels = katInfoDF['Label'].tolist()\n",
    "# list_of_values = katInfoDF['Value'].tolist()\n",
    "\n",
    "# list_of_questions = dataInfoDF['Label'].tolist()\n",
    "# list_of_quesNams = dataInfoDF['Variable'].tolist()\n",
    "\n",
    "# cleanedListOfStrings = hlp.get_cleaned_list_of_strings(list_of_questions, stemm=True)\n",
    "# cleanedListOfStrings\n",
    "# cleanedWordsArray = hlp.get_array_of_words(cleanedListOfStrings)\n",
    "\"\"\"\n",
    "get a list with qustions and answers for one patient\n",
    "\"\"\"\n",
    "# list_ques_answers = list(main_dict['1001'].values())\n",
    "# list_cleaned_ques_answers = hlp.get_cleaned_list_of_strings(list_ques_answers,stemm=False)\n",
    "# token_words_array = hlp.get_array_of_words(list_cleaned_ques_answers)\n",
    "# unique_token_words = np.unique(token_words_array, return_counts=True)\n",
    "# stemmed_by_nltk = hlp.get_stemmed_strings_as_nltk_SnowballStemmer(list_of_questions, ignore_stopwords=False)\n",
    "# tokenized_by_nltk =  hlp.get_tokenized_strings_by_nltk(cleanedListOfStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_with_dates = hlp.get_cols_with_dates(copy_rowdata)\n",
    "# df_dates_before = pd.DataFrame(columns=cols_with_dates)\n",
    "# df_dates_after = pd.DataFrame(columns=cols_with_dates)\n",
    "# for column in cols_with_dates:\n",
    "#     df_dates_before[column] = rowdataDF[column]\n",
    "#     df_dates_after[column] = copy_rowdata[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_rowdata.to_csv('C:/Users/a7mad/Desktop/MEX/PekLung/dates_adjusted.csv')\n",
    "copy_rowdata.to_excel('C:/Users/a7mad/Desktop/MEX/PekLung/dates_adjusted_excel.xlsx')\n",
    "# x = pd.read_csv('dates_adjusted.csv')\n",
    "# x = pd.read_excel('dates_adjusted_excel.xlsx')\n",
    "# del cols_with_dates, df_dates_after\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     display(df_dates_before)\n",
    "# display(df_dates_before)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):    \n",
    "#     display(df_dates_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most number of features removed is:  618\n",
      "patient index of most features removed is:  98\n",
      "Patient number: 1174, with remaining number of features: 65\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "get a dictionary of each patient according to this format:\n",
    "Patient number: {questions name, the questions text, corresponding answers}\n",
    "If clear_missings_or_Non true, it clears questions (features),\n",
    "where answeres are missing or the answers is no/missing\n",
    "\"\"\"\n",
    "main_dict, ind_num_removed_features = hlp.get_dict_of_questions_answers(copy_rowdata, \n",
    "                                                                        dataInfoDF, \n",
    "                                                                        katInfoDF, \n",
    "                                                                        amount_data = None,\n",
    "                                                                        clear_missings_or_Non=True)\n",
    "\"\"\"\n",
    "check how many features were removed by get_dict_of_questions_answers()\n",
    "You can calculate the actual number of features removed by:\n",
    "len(rowdataDF.loc[ind_of_max_feature_removed]) - len(main_dict[str(int(rowdataDF.loc[ind_of_max_feature_removed][0]))])-1\n",
    "obs! (-1 at the end to count for patient number which is not a feature).\n",
    "\"\"\"\n",
    "max_num_feature_removed = 0\n",
    "ind_of_max_feature_removed = 0\n",
    "\n",
    "for ind, count in ind_num_removed_features:\n",
    "    if count > max_num_feature_removed:\n",
    "        max_num_feature_removed = count\n",
    "        ind_of_max_feature_removed = ind\n",
    "print(\"most number of features removed is: \", max_num_feature_removed)\n",
    "print(\"patient index of most features removed is: \", ind_of_max_feature_removed)\n",
    "print(\"Patient number: {0}, with remaining number of features: {1}\".format(str(int(rowdataDF.loc[ind_of_max_feature_removed][0])), len(main_dict[str(int(rowdataDF.loc[ind_of_max_feature_removed][0]))])))\n",
    "\n",
    "#main_dict[str(int(rowdataDF.loc[ind_of_max_feature_removed][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In case you need to write/save the dictionary\n",
    "\"\"\"\n",
    "hlp.write_dict_as_json_file(main_dict)\n",
    "\n",
    "js = hlp.read_dict_from_json_file()\n",
    "js==main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = hlp.get_data_list_from_main_dict(main_dict, stemm=True)\n",
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = ml_hlp.get_tfidf_vectorization_model(data_list)\n",
    "# X_train_vectorized = ml_hlp.get_tfidf_vectorized_data(tfidf_model=vectorizer,\n",
    "#                                                       to_be_vectorized_data=data_list)\n",
    "# X_train = ml_hlp.get_csr_matrix(X_train_vectorized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
